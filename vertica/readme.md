#Vertica Benchmark


A set of bash style scripts to automate a Vertica benchmark using the LDBC Social Network data which can be found publicly on [ldbc_snb_datagen][1]. 

This benchmarking was conducted as part of a comparative study between three different database technologies, namely: Vertica; SqlGraph, running on MySQL; and Neo4J. The source code to these, together with a GUI style R-shinyapp representation of the acquired results can be found under the master branch.

##Script Structure

```html
Vertica/queries/				: Directory for test queries and scripts to automate repeat testing.
	   /vertica-ldbc-ingester/	: Main directory for ingestion script (1).
       /testResults/			: Raw data from multiple test runs with 1GB, 10GB, 30GB and 100GB data.
```

##Quick Start
To run the benchmark follow the numbered instructions below:

1: Generate the LDBC data and place in a know location on a Vertica node.

2: Create the multiple ingestion scripts for each data size. 

```bash
./vertica-ldbc-ingester/gen_ingestion.sh --ldbc "PATH to ldbc datagen dir"
```

For example:

```bash
./vertica-ldbc-ingester/gen_ingestion.sh --ldbc /media/1G/social_network
```

This will produce a ingestion.sql, move this file as per step 3.


3: Copy the ingestion.sql into the "queries/datascripts"" directory renamed to follow the form: ingestion1GB.sql for the 1GB data or ingestion3GB.sql (for 3GB).

4: Confirm the batchtest.sh (in Vertica/queries) has the correct data sizes set by checking the SIZE property. For example (1GB 3GB 10GB 30GB 100GB) will run the tests for 1,3,10,30,100GBs.

5: As a user with access to Vertica's "adminTools" (for example dbAdmin) run:

```bash
./batchtest.sh
```

This does the following:

```
For each size it will:
1. Check for the ingestion script is present
2. Remove the Vertica DB for this size (schema name is LDBCx{SIZE})
3. Create the Vertica DB for the size
4. Start the created DB
5. Execute the ingestion script for the DB size (which creates the schema, loads the data and gathers stats)
6. It waits 20 minutes for Vertica DB compression to finish
7. Gathers stats on the DB size
8. Executes the test query set (with and without cache)
9. Records the times
10. Runs the designer to generate the projections
11. Repeats steps 6, 7 & 8
12. Finally it stops the database
```
Results are outputted into a directory called "test" which has the following elements.

```html
test/totalSize.txt						: Stats on the size of the DB
    /withoutProjections					: Directory with the non projection timings in
    /withoutProjections/{SIZE}\NoCache	: NoCache results for the DB {SIZE} without projections
    /withoutProjections/{SIZE}\Cache	: NoCache results for the DB {SIZE} without projections
    /withProjections					: Directory with the projection timings in
    /withProjections/{SIZE}\Cache		: NoCache results for the DB {SIZE} with projections
    /withProjections/{SIZE}\NoCache		: NoCache results for the DB {SIZE} with projections
```


##Subdirectories
####queries

```html
queries\				: Main directory for benchmark script.
       \datascripts\		: Contains all ingestion sql generated by the gen_ingestion.sh for each data size.
       \batchtest.sh		: Runs the tests for each datasize
       \clear_cache.sql	    : SQL script to clear the database cache (used by the batchtest.sh).
       \run_designer.sh	    : script to run the designer against the schema based on the testing queries (used by the batchtest.sh).
       \query_test.sh		: Runs the query, no cache and then cached (used by the batchtest.sh).
```

**query_test.sh steps**
For each query that is tested the following steps are taken:

```html
1. The SQL cache is cleared, see clear_cache.sql.
2. The linux page caches are dropped using the following command on each node: sudo sh -c \"sync; echo 3 > /proc/sys/vm/drop_caches\"
3. The query is run and then step 2 is repeated $QUERY_REPEAT times (5 by default)
4. Stats are taken for the processing time.
5. Finally this is repeated but without the cache clearing
```


##Observations
####Vertica Tuning / Spec

###### Spec
The Vertica cluster we used was composed of three identical dedicated physical hosts, each of the hosts with the following specs:
```
2 x Intel Xeon CPU X5650 (6 real cores each @ 2.667 GHz)
L1 cache: 192 kB
L2 cache: 1536 kB
L3 cache: 12288 kB
RAM: 96GB @ 1333MHz
SCSI Disk, 15000 rpm, 2TB
```
The connection between the hosts was done with 1GB ethernet.
Ubuntu 14.04 LTS was running on every single host, with Vertica v7.2.

These specs are considerably inferior - in every single item - to the Vertica's recommended specs, available at [vertica_spec_reference][2]:

###### System Tuning

Only one change was made for the tuning of the cluster, which was to disable CPU frequency scaling on every single host and enable hyper threading.


The schema hasn't been enhanced / improved from the LDBC spec, other than the addition of projections.

--------

* As a last note, any suggestions, improvement or contribution to the code base are sincerely welcome.

[1]: https://github.com/ldbc/ldbc_snb_datagen
[2]: https://community.dev.hpe.com/t5/Vertica-Knowledge-Base/Recommendations-for-Sizing-Vertica-Nodes-and-Clusters/ta-p/233755
